{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import sklearn.neighbors as knn\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(tf.version.VERSION)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "    gpu = tf.config.experimental.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpu[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 32, 32, 1)\n",
      "(60000,)\n",
      "(10000, 32, 32, 1)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# load MNIST dataset\n",
    "# normalize data to 0~1 range\n",
    "data = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = data.load_data()\n",
    "\n",
    "x_train = np.pad(x_train, ((0,0), (2,2), (2,2)), 'constant', constant_values=0)\n",
    "x_train = x_train / 255.\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 32, 32, 1))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "x_test = np.pad(x_test, ((0,0), (2,2), (2,2)), 'constant', constant_values=0)\n",
    "x_test = x_test / 255.\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 32, 32, 1))\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lenet5_mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hand_writing_digit (InputLay [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "pool_1 (AveragePooling2D)    (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "pool_2 (AveragePooling2D)    (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "outputs (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load self-trained LeNet-5 model\n",
    "model_path = 'models/lenet5.h5'\n",
    "model_dir = os.path.dirname(model_path)\n",
    "lenet5_model = keras.models.load_model(model_dir)\n",
    "lenet5_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lenet5_mlp (Model)           (None, 10)                61706     \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "    lenet5_model,\n",
    "    tf.keras.layers.Softmax()\n",
    "])\n",
    "\n",
    "probability_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(x):\n",
    "    pred = probability_model(x)\n",
    "    indices = np.argmax(pred, axis=1)\n",
    "    scores = np.max(pred, axis=1)\n",
    "    return np.append([indices], [scores], axis=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9]\n",
      "[7. 2. 1. 0. 4. 1. 4. 9. 5. 9.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.        , 1.        ],\n",
       "       [2.        , 1.        ],\n",
       "       [1.        , 0.99999821],\n",
       "       [0.        , 0.99999988],\n",
       "       [4.        , 0.99992013],\n",
       "       [1.        , 1.        ],\n",
       "       [4.        , 0.99998486],\n",
       "       [9.        , 1.        ],\n",
       "       [5.        , 0.99455392],\n",
       "       [9.        , 1.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test prediction\n",
    "pred = get_predictions(x_test[:10])\n",
    "print(y_test[:10])\n",
    "print(pred[:,0])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 1)\n",
      "(10000,)\n",
      "10000/10000 - 0s - loss: 0.0434 - accuracy: 0.9898\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "loss, acc = lenet5_model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lenet5_encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hand_writing_digit (InputLay [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "pool_1 (AveragePooling2D)    (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "pool_2 (AveragePooling2D)    (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               48120     \n",
      "=================================================================\n",
      "Total params: 50,692\n",
      "Trainable params: 0\n",
      "Non-trainable params: 50,692\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# split model into encoder (convolutional layers) and dense-layer neural network\n",
    "# create encoder\n",
    "inputs = keras.Input(shape=(32,32,1), name='hand_writing_digit')\n",
    "x = keras.layers.Conv2D(filters=6, kernel_size=(5,5), activation='relu', name='conv2d_1')(inputs)\n",
    "x = keras.layers.AveragePooling2D((2,2), name='pool_1')(x)\n",
    "x = keras.layers.Conv2D(filters=16, kernel_size=(5,5), activation='relu', name='conv2d_2')(x)\n",
    "x = keras.layers.AveragePooling2D((2,2), name='pool_2')(x)\n",
    "x = keras.layers.Flatten(name='flatten')(x)\n",
    "outputs = keras.layers.Dense(120, activation='relu', name='dense_1')(x)\n",
    "\n",
    "encoder = keras.Model(inputs, outputs, name='lenet5_encoder')\n",
    "\n",
    "# load weights and loack the trained weights\n",
    "for encoder_layer, lenet5_layer in zip(encoder.layers, lenet5_model.layers[:7]):\n",
    "    encoder_layer.set_weights(lenet5_layer.get_weights())\n",
    "    encoder_layer.trainable = False\n",
    "\n",
    "# we don't compile encoder, since there's nothing to train the results are in the middel of LeNet-5\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed layer comparision test\n"
     ]
    }
   ],
   "source": [
    "# check weights\n",
    "for encoder_layer, lenet5_layer in zip(encoder.layers, lenet5_model.layers[:7]):\n",
    "    if len(encoder_layer.get_weights()) is not 0:\n",
    "        result = np.array_equal(\n",
    "            encoder_layer.get_weights()[0],\n",
    "            lenet5_layer.get_weights()[0])\n",
    "        if result is not True:\n",
    "            raise Exception('Unmatched weights')\n",
    "\n",
    "print('Passed layer comparision test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_nn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_img (InputLayer)     [(None, 120)]             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "outputs (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 11,014\n",
      "Trainable params: 0\n",
      "Non-trainable params: 11,014\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create dense-layer model\n",
    "inputs = keras.Input(shape=(120,), name='encoded_img')\n",
    "x = keras.layers.Dense(84, activation='relu', name='dense_2')(inputs)\n",
    "outputs = keras.layers.Dense(10, name='outputs')(x)\n",
    "\n",
    "dense_nn_model = keras.Model(inputs, outputs, name='dense_nn')\n",
    "\n",
    "# load weights and loack the trained weights\n",
    "for empty_layer, lenet5_layer in zip(dense_nn_model.layers[1:], lenet5_model.layers[-2:]):\n",
    "    empty_layer.set_weights(lenet5_layer.get_weights())\n",
    "    empty_layer.trainable = False\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "dense_nn_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=loss_fn,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "dense_nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed layer comparision test\n"
     ]
    }
   ],
   "source": [
    "# check weights\n",
    "for clone_layer, lenet5_layer in zip(dense_nn_model.layers[1:], lenet5_model.layers[-2:]):\n",
    "    if len(encoder_layer.get_weights()) is not 0:\n",
    "        result = np.array_equal(\n",
    "            clone_layer.get_weights()[0],\n",
    "            lenet5_layer.get_weights()[0])\n",
    "        if result is not True:\n",
    "            raise Exception('Unmatched weights')\n",
    "\n",
    "print('Passed layer comparision test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.0434 - accuracy: 0.9898\n"
     ]
    }
   ],
   "source": [
    "# use the coder and dense_nn models together\n",
    "lenet5_test_acc = 0.9898\n",
    "\n",
    "encoded_test = encoder.predict(x_test)\n",
    "loss, acc = dense_nn_model.evaluate(encoded_test, y_test, verbose=2)\n",
    "\n",
    "if not math.isclose(lenet5_test_acc, acc, rel_tol=1e-6):\n",
    "    raise Exception('Unmatched accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Adversarial examples using FGSM\n",
    "https://www.tensorflow.org/tutorials/generative/adversarial_fgsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use probability loss function instead of scalar\n",
    "loss_fn_adv = keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "def create_adversarial_perturbation(input_img, input_probs):\n",
    "    if input_img.shape != (32, 32, 1):\n",
    "        raise Exception('Image size does not match', input_img.shape)\n",
    "    if input_probs.shape != (1, 10):\n",
    "        raise Exception('Probabilities should be a row vector', input_probs.shape)\n",
    "    \n",
    "    x = tf.convert_to_tensor([input_img])\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x)\n",
    "        pred = lenet5_model(x)\n",
    "        loss = loss_fn_adv(input_probs, pred)\n",
    "    \n",
    "    gradient = tape.gradient(loss, x)\n",
    "    signed_grad = tf.sign(gradient)\n",
    "    return signed_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2311\n",
      "Ture label: 2\n",
      "Prediction: [[2. 1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f13416b29e8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# idx = np.random.randint(0, len(y_test))\n",
    "idx = 2311\n",
    "print(idx)\n",
    "print('Ture label:', y_test[idx])\n",
    "pred = get_predictions(np.array([x_test[idx]]))\n",
    "print('Prediction:', pred)\n",
    "plt.figure()\n",
    "plt.imshow(x_test[idx,:,:,0], cmap='Greys', vmin=0, vmax=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = x_test[idx]\n",
    "# use prediction from the model instead of true label\n",
    "pred = lenet5_model(tf.convert_to_tensor([img]))\n",
    "perturbation = create_adversarial_perturbation(img, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1341097588>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(perturbation[0,:,:,0], cmap='Greys', vmin=-1., vmax=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1340ff7b38>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epsilon = 0.15\n",
    "adv_x = img + epsilon * perturbation\n",
    "# limited range to 0 and 1\n",
    "adv_x = tf.clip_by_value(adv_x, 0, 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(adv_x[0,:,:,0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.294967e-15 5.663049e-16 1.0 2.105762e-17 3.899199e-15 3.185205e-21 1.5086514e-16 5.939667e-10 2.369382e-22 1.2140292e-19\n",
      "[[2. 1.]]\n",
      "9.797733e-16 3.0924505e-09 2.6389846e-06 1.091792e-09 2.1987772e-09 7.346489e-14 9.599356e-17 0.9999974 4.477096e-16 9.385238e-09\n",
      "[[7.         0.99999738]]\n",
      "Successfully found adversarial example\n"
     ]
    }
   ],
   "source": [
    "probs = probability_model(tf.convert_to_tensor([img]))\n",
    "pred = get_predictions(tf.convert_to_tensor([img]))\n",
    "print(*probs.numpy()[0])\n",
    "print(pred)\n",
    "\n",
    "adv_prbos = probability_model(adv_x)\n",
    "adv_pred = get_predictions(tf.convert_to_tensor(adv_x))\n",
    "print(*adv_prbos.numpy()[0])\n",
    "print(adv_pred)\n",
    "\n",
    "if pred[0][0] != adv_pred[0][0]:\n",
    "    print('Successfully found adversarial example')\n",
    "else:\n",
    "    print(f'Failed to find adversarial example from index {idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the progress bar\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lukec/workspace/jupyter_tensorflow/data\n"
     ]
    }
   ],
   "source": [
    "# try to load saved file\n",
    "folder_path = os.getcwd()\n",
    "adv_path = folder_path + '/data/saved_adv.npy'\n",
    "adv_dir = os.path.dirname(adv_path)\n",
    "print(adv_dir)\n",
    "if not os.path.exists(adv_dir):\n",
    "    os.mkdir(adv_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating adversarial examples on entire test set\n",
    "count = len(y_test)\n",
    "adv_test = np.empty((0, 32, 32, 1), dtype=np.float32)\n",
    "pred_test = lenet5_model(tf.convert_to_tensor(x_test))\n",
    "epsilon = 0.15\n",
    "\n",
    "if not os.path.isfile(adv_path):\n",
    "    with tqdm(total=count) as pbar:\n",
    "        for i in range(count):\n",
    "            pred_og = tf.convert_to_tensor([pred_test[i]])\n",
    "            perturbation = create_adversarial_perturbation(x_test[i], pred_og)\n",
    "            perturbation = perturbation.numpy()[0]\n",
    "            adv = x_test[i] + epsilon * perturbation\n",
    "\n",
    "            # apply clipping\n",
    "            # adv = tf.clip_by_value(adv, 0, 1)\n",
    "            adv_test = np.append(adv_test, [adv], axis=0)\n",
    "            if i % 10 == 0:\n",
    "                pbar.update(10)\n",
    "    np.save(adv_path, adv_test)\n",
    "else:\n",
    "    adv_test = np.load(adv_path, mmap_mode='r')\n",
    "\n",
    "adv_test.shape\n",
    "# loss, acc = lenet5_model.evaluate(adv_test[:50], y_test[:50], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 1.7135 - accuracy: 0.8017\n"
     ]
    }
   ],
   "source": [
    "loss, acc = lenet5_model.evaluate(adv_test, y_test[:count], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import applicability_domain as ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.        , 0.99999869],\n",
       "       [2.        , 0.99999702],\n",
       "       [1.        , 0.99896634],\n",
       "       [0.        , 1.        ],\n",
       "       [9.        , 0.9999913 ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this variable combines the predicted label and its probability\n",
    "adv_pred_label = get_predictions(adv_test)\n",
    "adv_pred_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- Applicability ---------------\n",
      "Note: Instead of block it, we use the bounding box to clip and rescale the inputs.\n",
      "(10000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Stage 1 - Applicability\n",
    "print('\\n---------- Applicability ---------------')\n",
    "print('Note: Instead of block it, we use the bounding box to clip and rescale the inputs.')\n",
    "# apply clipping\n",
    "ad_test = tf.clip_by_value(adv_test, 0., 1.)\n",
    "\n",
    "# apply 8-bit rescaling\n",
    "ad_test = tf.round(ad_test * 255.) / 255.\n",
    "print(ad_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- Reliability -----------------\n",
      "Parameters: k = 12, zeta = 0.4\n"
     ]
    }
   ],
   "source": [
    "# Stage 2 - Reliability\n",
    "# parameters for Reliability Stage\n",
    "k = 12\n",
    "zeta = 0.4 \n",
    "\n",
    "print('\\n---------- Reliability -----------------')\n",
    "print(f'Parameters: k = {k}, zeta = {zeta}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "# the clean train set after encoding\n",
    "encoded_train = encoder.predict(x_train)\n",
    "encoded_ad = encoder.predict(ad_test)\n",
    "\n",
    "knn_models = []\n",
    "# mu, sd, and are scalar for each label\n",
    "means = np.empty((10), dtype=np.float32)\n",
    "std_devs = np.empty((10), dtype=np.float32)\n",
    "\n",
    "num_labels = 10\n",
    "with tqdm(total=num_labels) as pbar:\n",
    "    for i in range(num_labels):\n",
    "        indices = np.where(y_train == i)\n",
    "        # creating kNN models for each class\n",
    "        knn_model = utils.unimodal_knn(encoded_train[indices], k)\n",
    "        knn_models.append(knn_model)\n",
    "\n",
    "        # computing mean, standard deviation and threshold\n",
    "        mu, sd = utils.get_distance_info(\n",
    "            knn_models[i], encoded_train[indices], k, seen_in_train_set=True)\n",
    "        means[i] = mu\n",
    "        std_devs[i] = sd\n",
    "        \n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for easier to adjust zeta\n",
    "# threshold is a scalar for each label\n",
    "thresholds = np.empty((10), dtype=np.float32)\n",
    "\n",
    "for i in range(10):\n",
    "    thresholds[i] = ad.get_reliability_threshold(mu, sd, zeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3114, 120)\n",
      "(3114,)\n"
     ]
    }
   ],
   "source": [
    "encoded_passed_s2, indices_passed_s2 = ad.check_reliability(\n",
    "    encoded_ad,\n",
    "    predictions=adv_pred_label[:,0],\n",
    "    models=knn_models,\n",
    "    dist_thresholds=thresholds,\n",
    "    classes=list(range(10)),\n",
    "    verbose=0\n",
    ")\n",
    "print(encoded_passed_s2.shape)\n",
    "print(indices_passed_s2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3114/3114 - 0s - loss: 0.3306 - accuracy: 0.9663\n",
      "After reliability check:\n",
      "Blocked 6886 samples\n",
      "Pass rate = 31.1400%\n",
      "\n",
      "# of missclassified = 105\n",
      "\n",
      "Confusion matrix\n",
      "Actual classes\n",
      "    0   1   2   3   4   5   6   7   8   9\n",
      "[[495   0   0   0   0   0   0   0   0   0]\n",
      " [  0 848   1   0   0   0   2   1   4   0]\n",
      " [  0   0  15   0   0   0   0   1   1   0]\n",
      " [  0   0   0 104   0   1   0   0   1   0]\n",
      " [  0   0   0   0 176   0   2   0   0  45]\n",
      " [  0   0   0   0   0  19   1   0   0   0]\n",
      " [  2   0   0   0   0   0 407   0   0   0]\n",
      " [  0   0   0   0   0   0   0 163   0  19]\n",
      " [  0   1   0   1   0   0   0   0 372   1]\n",
      " [  0   0   0   0  15   0   0   4   2 410]]\n"
     ]
    }
   ],
   "source": [
    "# Stage 2 result\n",
    "loss, acc = lenet5_model.evaluate(\n",
    "    ad_test.numpy()[indices_passed_s2], \n",
    "    y_test[indices_passed_s2], \n",
    "    verbose=2)\n",
    "print('After reliability check:')\n",
    "print(f'Blocked {len(adv_test) - len(indices_passed_s2)} samples')\n",
    "pass_rate = utils.get_rate(encoded_passed_s2, adv_test)\n",
    "print(f'Pass rate = {pass_rate * 100:.4f}%')\n",
    "\n",
    "pred_passed = get_predictions(ad_test.numpy()[indices_passed_s2])\n",
    "conf_mat = metrics.confusion_matrix(y_test[indices_passed_s2], pred_passed[:,0])\n",
    "count_mis = len(np.where(np.not_equal(y_test[indices_passed_s2], pred_passed[:,0]))[0])\n",
    "print(f'\\n# of missclassified = {count_mis}')\n",
    "\n",
    "print('\\nConfusion matrix')\n",
    "print('Actual classes')\n",
    "print(' ', *list(range(10)), sep='   ')\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- Decidability ----------------\n",
      "Parameters: k = 32\n"
     ]
    }
   ],
   "source": [
    "# Stage 3 - Decidability\n",
    "# parameters for Decidability Stage\n",
    "k2 = 32\n",
    "\n",
    "print('\\n---------- Decidability ----------------')\n",
    "print(f'Parameters: k = {k2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=-1, n_neighbors=32, p=2,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the knnn model with complete train set\n",
    "comp_knn_model = knn.KNeighborsClassifier(\n",
    "    n_neighbors=k2,\n",
    "    n_jobs=-1,\n",
    "    weights='distance'\n",
    ")\n",
    "comp_knn_model.fit(encoded_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set  = 99.1700%\n"
     ]
    }
   ],
   "source": [
    "pred_test = comp_knn_model.predict(encoded_test)\n",
    "score_test = metrics.accuracy_score(y_test, pred_test)\n",
    "print(f'Accuracy of KNN on clean test set  = {score_test*100:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample passed in: (3114, 2)\n",
      "(3109, 120)\n",
      "(3109,)\n"
     ]
    }
   ],
   "source": [
    "pred_passed = get_predictions(ad_test.numpy()[indices_passed_s2])\n",
    "print('sample passed in:', pred_passed.shape)\n",
    "\n",
    "encoded_passed_s3, indices_passed_s3 = ad.check_decidability(\n",
    "    encoded_passed_s2,\n",
    "    pred_passed[:,0],\n",
    "    comp_knn_model\n",
    ")\n",
    "indices_passed_s3 = indices_passed_s3[0]\n",
    "\n",
    "print(encoded_passed_s3.shape)\n",
    "print(indices_passed_s3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3109/3109 - 0s - loss: 0.9638 - accuracy: 0.8430\n",
      "After reliability check:\n",
      "Blocked 5 samples\n",
      "Pass rate = 31.0900%\n",
      "\n",
      "# of samples after AD = 3109\n",
      "Total blocked samples = 6891\n"
     ]
    }
   ],
   "source": [
    "# Stage 3 result\n",
    "loss, acc = lenet5_model.evaluate(\n",
    "    ad_test.numpy()[indices_passed_s3], \n",
    "    y_test[indices_passed_s3], \n",
    "    verbose=2)\n",
    "print('After reliability check:')\n",
    "print(f'Blocked {len(indices_passed_s2) - len(indices_passed_s3)} samples')\n",
    "pass_rate = utils.get_rate(encoded_passed_s3, adv_test)\n",
    "print(f'Pass rate = {pass_rate * 100:.4f}%')\n",
    "\n",
    "print(f'\\n# of samples after AD = {len(indices_passed_s3)}')\n",
    "print(f'Total blocked samples = {len(y_test) - len(indices_passed_s3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of missclassified = 488\n",
      "\n",
      "Confusion matrix\n",
      "Actual classes\n",
      "    0   1   2   3   4   5   6   7   8   9\n",
      "[[268   0   2   0   1   1   4   0   1   4]\n",
      " [  0 339   0   6   0   0   3   3   1   0]\n",
      " [  4   2 297   1   1   0   1  17   0   0]\n",
      " [  0   0   3 295   0  25   0   3   1   2]\n",
      " [  0   0   1   0 206   0   3   0   0 117]\n",
      " [  0   0   0  18   0 240   8   0   4  22]\n",
      " [  5   0   1   0   8  23 246   0   0   0]\n",
      " [  0   0   4   2   3   0   0 226   0  87]\n",
      " [  1   1   6  10   2  12   2   1 257   4]\n",
      " [  0   0   0   5  44   3   0   4   1 247]]\n"
     ]
    }
   ],
   "source": [
    "pred_passed = get_predictions(ad_test.numpy()[indices_passed_s3])\n",
    "conf_mat = metrics.confusion_matrix(y_test[indices_passed_s3], pred_passed[:,0])\n",
    "count_mis = len(np.where(np.not_equal(y_test[indices_passed_s3], pred_passed[:,0]))[0])\n",
    "print(f'# of missclassified = {count_mis}')\n",
    "\n",
    "print('\\nConfusion matrix')\n",
    "print('Actual classes')\n",
    "print(' ', *list(range(10)), sep='   ')\n",
    "print(conf_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
