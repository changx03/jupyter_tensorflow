{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "print(tf.version.VERSION)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "    gpu = tf.config.experimental.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpu[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 32, 32, 1)\n",
      "(60000,)\n",
      "(10000, 32, 32, 1)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# load MNIST dataset\n",
    "# normalize data to 0~1 range\n",
    "data = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = data.load_data()\n",
    "\n",
    "x_train = np.pad(x_train, ((0,0), (2,2), (2,2)), 'constant', constant_values=0)\n",
    "x_train = x_train / 255.\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 32, 32, 1))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "x_test = np.pad(x_test, ((0,0), (2,2), (2,2)), 'constant', constant_values=0)\n",
    "x_test = x_test / 255.\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 32, 32, 1))\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lenet5_mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hand_writing_digit (InputLay [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "pool_1 (AveragePooling2D)    (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "pool_2 (AveragePooling2D)    (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "outputs (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load self-trained LeNet-5 model\n",
    "model_path = 'models/lenet5.h5'\n",
    "model_dir = os.path.dirname(model_path)\n",
    "lenet5_model = keras.models.load_model(model_dir)\n",
    "lenet5_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lenet5_mlp (Model)           (None, 10)                61706     \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "    lenet5_model,\n",
    "    tf.keras.layers.Softmax()\n",
    "])\n",
    "\n",
    "probability_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(x):\n",
    "    pred = probability_model(x)\n",
    "    indeces = np.argmax(pred, axis=1)\n",
    "    scores = np.max(pred, axis=1)\n",
    "    return list(zip(indeces, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9]\n",
      "[7 2 1 0 4 1 4 9 5 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(7, 1.0),\n",
       " (2, 1.0),\n",
       " (1, 0.9999982),\n",
       " (0, 0.9999999),\n",
       " (4, 0.9999201),\n",
       " (1, 1.0),\n",
       " (4, 0.99998486),\n",
       " (9, 1.0),\n",
       " (5, 0.9945539),\n",
       " (9, 1.0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test prediction\n",
    "pred = get_predictions(x_test[:10])\n",
    "print(y_test[:10])\n",
    "print(np.array([p[0] for p in pred]))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.0434 - accuracy: 0.9898\n"
     ]
    }
   ],
   "source": [
    "loss, acc = lenet5_model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lenet5_encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hand_writing_digit (InputLay [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "pool_1 (AveragePooling2D)    (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "pool_2 (AveragePooling2D)    (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               48120     \n",
      "=================================================================\n",
      "Total params: 50,692\n",
      "Trainable params: 0\n",
      "Non-trainable params: 50,692\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# split model into encoder (convolutional layers) and dense-layer neural network\n",
    "# create encoder\n",
    "inputs = keras.Input(shape=(32,32,1), name='hand_writing_digit')\n",
    "x = keras.layers.Conv2D(filters=6, kernel_size=(5,5), activation='relu', name='conv2d_1')(inputs)\n",
    "x = keras.layers.AveragePooling2D((2,2), name='pool_1')(x)\n",
    "x = keras.layers.Conv2D(filters=16, kernel_size=(5,5), activation='relu', name='conv2d_2')(x)\n",
    "x = keras.layers.AveragePooling2D((2,2), name='pool_2')(x)\n",
    "x = keras.layers.Flatten(name='flatten')(x)\n",
    "outputs = keras.layers.Dense(120, activation='relu', name='dense_1')(x)\n",
    "\n",
    "encoder = keras.Model(inputs, outputs, name='lenet5_encoder')\n",
    "\n",
    "# load weights and loack the trained weights\n",
    "for encoder_layer, lenet5_layer in zip(encoder.layers, lenet5_model.layers[:7]):\n",
    "    encoder_layer.set_weights(lenet5_layer.get_weights())\n",
    "    encoder_layer.trainable = False\n",
    "\n",
    "# we don't compile encoder, since there's nothing to train the results are in the middel of LeNet-5\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed layer comparision test\n"
     ]
    }
   ],
   "source": [
    "# check weights\n",
    "for encoder_layer, lenet5_layer in zip(encoder.layers, lenet5_model.layers[:7]):\n",
    "    if len(encoder_layer.get_weights()) is not 0:\n",
    "        result = np.array_equal(\n",
    "            encoder_layer.get_weights()[0],\n",
    "            lenet5_layer.get_weights()[0])\n",
    "        if result is not True:\n",
    "            raise Exception('Unmatched weights')\n",
    "\n",
    "print('Passed layer comparision test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_nn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_img (InputLayer)     [(None, 120)]             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "outputs (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 11,014\n",
      "Trainable params: 0\n",
      "Non-trainable params: 11,014\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create dense-layer model\n",
    "inputs = keras.Input(shape=(120,), name='encoded_img')\n",
    "x = keras.layers.Dense(84, activation='relu', name='dense_2')(inputs)\n",
    "outputs = keras.layers.Dense(10, name='outputs')(x)\n",
    "\n",
    "dense_nn_model = keras.Model(inputs, outputs, name='dense_nn')\n",
    "\n",
    "# load weights and loack the trained weights\n",
    "for empty_layer, lenet5_layer in zip(dense_nn_model.layers[1:], lenet5_model.layers[-2:]):\n",
    "    empty_layer.set_weights(lenet5_layer.get_weights())\n",
    "    empty_layer.trainable = False\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "dense_nn_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=loss_fn,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "dense_nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed layer comparision test\n"
     ]
    }
   ],
   "source": [
    "# check weights\n",
    "for clone_layer, lenet5_layer in zip(dense_nn_model.layers[1:], lenet5_model.layers[-2:]):\n",
    "    if len(encoder_layer.get_weights()) is not 0:\n",
    "        result = np.array_equal(\n",
    "            clone_layer.get_weights()[0],\n",
    "            lenet5_layer.get_weights()[0])\n",
    "        if result is not True:\n",
    "            raise Exception('Unmatched weights')\n",
    "\n",
    "print('Passed layer comparision test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.0434 - accuracy: 0.9898\n"
     ]
    }
   ],
   "source": [
    "# use the coder and dense_nn models together\n",
    "lenet5_test_acc = 0.9898\n",
    "\n",
    "encoded_test = encoder.predict(x_test)\n",
    "loss, acc = dense_nn_model.evaluate(encoded_test, y_test, verbose=2)\n",
    "\n",
    "if not math.isclose(lenet5_test_acc, acc, rel_tol=1e-6):\n",
    "    raise Exception('Unmatched accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Adversarial examples using FGSM\n",
    "https://www.tensorflow.org/tutorials/generative/adversarial_fgsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adversarial_perturbation(input_img, label):\n",
    "    if input_img.shape != (32, 32, 1):\n",
    "        raise Exception('Image size does not match', input_img.shape)\n",
    "    if not np.isscalar(label):\n",
    "        raise Exception('Label is a scalar')\n",
    "    \n",
    "    x = tf.convert_to_tensor([input_img])\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x)\n",
    "        pred = lenet5_model(x)\n",
    "        loss = loss_fn(tf.convert_to_tensor(label), pred)\n",
    "    \n",
    "    gradient = tape.gradient(loss, x)\n",
    "    signed_grad = tf.sign(gradient)\n",
    "    return signed_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n",
      "Ture label: 1\n",
      "Prediction: [(1, 0.9999943)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff76f4098d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# idx = np.random.randint(0, len(y_test))\n",
    "idx = 143\n",
    "print(idx)\n",
    "print('Ture label:', y_test[idx])\n",
    "pred = get_predictions(np.array([x_test[idx]]))\n",
    "print('Prediction:', pred)\n",
    "plt.figure()\n",
    "plt.imshow(x_test[idx,:,:,0], cmap='Greys', vmin=0, vmax=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = x_test[idx]\n",
    "label = y_test[idx]\n",
    "pred = lenet5_model(tf.convert_to_tensor([img]))\n",
    "perturbation = create_adversarial_perturbation(img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff76ee26fd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epsilon = 0.15\n",
    "adv_x = img + epsilon * perturbation\n",
    "# limited range to 0 and 1\n",
    "adv_x = tf.clip_by_value(adv_x, 0, 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(adv_x[0,:,:,0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8392264e-10 0.9999943 4.4899596e-07 8.7938054e-15 7.869149e-08 4.076708e-09 2.7621729e-08 2.5244198e-09 5.100235e-06 1.9555017e-11\n",
      "[(1, 0.9999943)]\n",
      "2.3488358e-06 0.058108985 0.0011522063 1.4968958e-08 8.560731e-05 3.7675227e-06 5.637507e-07 2.049887e-06 0.9406421 2.3772893e-06\n",
      "[(8, 0.9406421)]\n"
     ]
    }
   ],
   "source": [
    "pred = probability_model(tf.convert_to_tensor([img]))\n",
    "print(*pred.numpy()[0])\n",
    "print(get_predictions(tf.convert_to_tensor([img])))\n",
    "\n",
    "\n",
    "adv_pred = probability_model(adv_x)\n",
    "print(*adv_pred.numpy()[0])\n",
    "print(get_predictions(tf.convert_to_tensor(adv_x)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
