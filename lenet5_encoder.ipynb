{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "print(tf.version.VERSION)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "    gpu = tf.config.experimental.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpu[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "(60000, 32, 32, 1)\n",
      "(60000,)\n",
      "(10000, 32, 32, 1)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# load MNIST dataset\n",
    "# normalize data to 0~1 range\n",
    "data = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = data.load_data()\n",
    "\n",
    "x_train = np.pad(x_train, ((0,0), (2,2), (2,2)), 'constant', constant_values=0)\n",
    "x_train = x_train / 255.\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 32, 32, 1))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "x_test = np.pad(x_test, ((0,0), (2,2), (2,2)), 'constant', constant_values=0)\n",
    "x_test = x_test / 255.\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 32, 32, 1))\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lenet5_mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hand_writing_digit (InputLay [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "pool_1 (AveragePooling2D)    (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "pool_2 (AveragePooling2D)    (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "outputs (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load self-trained LeNet-5 model\n",
    "model_path = 'models/lenet5.h5'\n",
    "model_dir = os.path.dirname(model_path)\n",
    "lenet5_model = keras.models.load_model(model_dir)\n",
    "lenet5_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "    lenet5_model,\n",
    "    tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(x):\n",
    "    pred = probability_model(x)\n",
    "    indeces = np.argmax(pred, axis=1)\n",
    "    scores = np.max(pred, axis=1)\n",
    "    return list(zip(indeces, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9]\n",
      "[7 2 1 0 4 1 4 9 5 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(7, 1.0),\n",
       " (2, 1.0),\n",
       " (1, 0.9999982),\n",
       " (0, 0.9999999),\n",
       " (4, 0.9999201),\n",
       " (1, 1.0),\n",
       " (4, 0.99998486),\n",
       " (9, 1.0),\n",
       " (5, 0.9945539),\n",
       " (9, 1.0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test prediction\n",
    "pred = get_predictions(x_test[:10])\n",
    "print(y_test[:10])\n",
    "print(np.array([p[0] for p in pred]))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 1s - loss: 0.0434 - accuracy: 0.9898\n"
     ]
    }
   ],
   "source": [
    "loss, acc = lenet5_model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lenet5_encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hand_writing_digit (InputLay [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "pool_1 (AveragePooling2D)    (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "pool_2 (AveragePooling2D)    (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               48120     \n",
      "=================================================================\n",
      "Total params: 50,692\n",
      "Trainable params: 0\n",
      "Non-trainable params: 50,692\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# split model into encoder (convolutional layers) and dense-layer neural network\n",
    "# create encoder\n",
    "inputs = keras.Input(shape=(32,32,1), name='hand_writing_digit')\n",
    "x = keras.layers.Conv2D(filters=6, kernel_size=(5,5), activation='relu', name='conv2d_1')(inputs)\n",
    "x = keras.layers.AveragePooling2D((2,2), name='pool_1')(x)\n",
    "x = keras.layers.Conv2D(filters=16, kernel_size=(5,5), activation='relu', name='conv2d_2')(x)\n",
    "x = keras.layers.AveragePooling2D((2,2), name='pool_2')(x)\n",
    "x = keras.layers.Flatten(name='flatten')(x)\n",
    "outputs = keras.layers.Dense(120, activation='relu', name='dense_1')(x)\n",
    "\n",
    "encoder = keras.Model(inputs, outputs, name='lenet5_encoder')\n",
    "\n",
    "# load weights and loack the trained weights\n",
    "for encoder_layer, lenet5_layer in zip(encoder.layers, lenet5_model.layers[:7]):\n",
    "    encoder_layer.set_weights(lenet5_layer.get_weights())\n",
    "    encoder_layer.trainable = False\n",
    "\n",
    "# we don't compile encoder, since there's nothing to train the results are in the middel of LeNet-5\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed layer comparision test\n"
     ]
    }
   ],
   "source": [
    "# check weights\n",
    "for encoder_layer, lenet5_layer in zip(encoder.layers, lenet5_model.layers[:7]):\n",
    "    if len(encoder_layer.get_weights()) is not 0:\n",
    "        result = np.array_equal(\n",
    "            encoder_layer.get_weights()[0],\n",
    "            lenet5_layer.get_weights()[0])\n",
    "        if result is not True:\n",
    "            raise Exception('Unmatched weights')\n",
    "\n",
    "print('Passed layer comparision test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_nn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_img (InputLayer)     [(None, 120)]             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "outputs (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 11,014\n",
      "Trainable params: 0\n",
      "Non-trainable params: 11,014\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create dense-layer model\n",
    "inputs = keras.Input(shape=(120,), name='encoded_img')\n",
    "x = keras.layers.Dense(84, activation='relu', name='dense_2')(inputs)\n",
    "outputs = keras.layers.Dense(10, name='outputs')(x)\n",
    "\n",
    "dense_nn_model = keras.Model(inputs, outputs, name='dense_nn')\n",
    "\n",
    "# load weights and loack the trained weights\n",
    "for empty_layer, lenet5_layer in zip(dense_nn_model.layers[1:], lenet5_model.layers[-2:]):\n",
    "    empty_layer.set_weights(lenet5_layer.get_weights())\n",
    "    empty_layer.trainable = False\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "dense_nn_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=loss_fn,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "dense_nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed layer comparision test\n"
     ]
    }
   ],
   "source": [
    "# check weights\n",
    "for clone_layer, lenet5_layer in zip(dense_nn_model.layers[1:], lenet5_model.layers[-2:]):\n",
    "    if len(encoder_layer.get_weights()) is not 0:\n",
    "        result = np.array_equal(\n",
    "            clone_layer.get_weights()[0],\n",
    "            lenet5_layer.get_weights()[0])\n",
    "        if result is not True:\n",
    "            raise Exception('Unmatched weights')\n",
    "\n",
    "print('Passed layer comparision test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.0434 - accuracy: 0.9898\n"
     ]
    }
   ],
   "source": [
    "# use the coder and dense_nn models together\n",
    "lenet5_test_acc = 0.9898\n",
    "\n",
    "encoded_test = encoder.predict(x_test)\n",
    "loss, acc = dense_nn_model.evaluate(encoded_test, y_test, verbose=2)\n",
    "\n",
    "if not math.isclose(lenet5_test_acc, acc, rel_tol=1e-6):\n",
    "    raise Exception('Unmatched accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Adversarial examples using FGSM\n",
    "# https://www.tensorflow.org/tutorials/generative/adversarial_fgsm\n",
    "def create_adversarial_examples(img, label):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(img)\n",
    "        pred = lenet5_model(img)\n",
    "        loss = loss_fn(label, pred)\n",
    "    \n",
    "    gradient = tape.gradient(loss, img)\n",
    "    signed_grad = tf.sign(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6509\n",
      "Ture label: 6\n",
      "Prediction: [(6, 1.0)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f72bc766b50>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(0, len(y_test))\n",
    "print(idx)\n",
    "print('Ture label:', y_test[idx])\n",
    "pred = get_predictions(np.array([x_test[idx]]))\n",
    "print('Prediction:', pred)\n",
    "plt.figure()\n",
    "plt.imshow(x_test[idx,:,:,0], cmap='Greys', vmin=0, vmax=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 1)\n",
      "(1, 10)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch: The shape of labels (received (10,)) should equal the shape of logits except for the last dimension (received (1, 10)).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-caa611433402>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mExcpetion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Shape mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# gradient = tape.gradient(loss, img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    124\u001b[0m         y_true, y_pred, sample_weight)\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope_name\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m       \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m       return losses_utils.compute_weighted_loss(\n\u001b[1;32m    128\u001b[0m           losses, sample_weight, reduction=self._get_reduction())\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    219\u001b[0m       y_pred, y_true = tf_losses_util.squeeze_or_expand_dimensions(\n\u001b[1;32m    220\u001b[0m           y_pred, y_true)\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py\u001b[0m in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, axis)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msparse_categorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m   return K.sparse_categorical_crossentropy(\n\u001b[0;32m--> 978\u001b[0;31m       y_true, y_pred, from_logits=from_logits, axis=axis)\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m   4574\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4575\u001b[0m     res = nn.sparse_softmax_cross_entropy_with_logits_v2(\n\u001b[0;32m-> 4576\u001b[0;31m         labels=target, logits=output)\n\u001b[0m\u001b[1;32m   4577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4578\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mupdate_shape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moutput_rank\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits_v2\u001b[0;34m(labels, logits, name)\u001b[0m\n\u001b[1;32m   3535\u001b[0m   \"\"\"\n\u001b[1;32m   3536\u001b[0m   return sparse_softmax_cross_entropy_with_logits(\n\u001b[0;32m-> 3537\u001b[0;31m       labels=labels, logits=logits, name=name)\n\u001b[0m\u001b[1;32m   3538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[1;32m   3451\u001b[0m                        \u001b[0;34m\"should equal the shape of logits except for the last \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3452\u001b[0m                        \"dimension (received %s).\" % (labels_static_shape,\n\u001b[0;32m-> 3453\u001b[0;31m                                                      logits.get_shape()))\n\u001b[0m\u001b[1;32m   3454\u001b[0m     \u001b[0;31m# Check if no reshapes are required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3455\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape mismatch: The shape of labels (received (10,)) should equal the shape of logits except for the last dimension (received (1, 10))."
     ]
    }
   ],
   "source": [
    "img = x_test[idx]\n",
    "img = tf.cast(img, tf.float32)\n",
    "print(img.shape)\n",
    "probs = lenet5_model(tf.cast([img], tf.float32))\n",
    "print(probs.shape)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(img)\n",
    "    pred = lenet5_model(tf.cast([img], tf.float32))\n",
    "    if probs.shape != pred.shape:\n",
    "        raise Excpetion('Shape mismatch')\n",
    "    loss = loss_fn(y_true=probs, y_pred=pred)\n",
    "\n",
    "# gradient = tape.gradient(loss, img)\n",
    "\n",
    "# signed_grad = tf.sign(gradient)\n",
    "# perturbations = create_adversarial_examples(x_test[idx], probs)\n",
    "# print(pertubations.shape)\n",
    "# plt.imshow(perturbations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Ture: {y_test[idx]}, Prediction: {pred[idx]}')\n",
    "plt.figure()\n",
    "plt.imshow(x_test[index,:,:,0], cmap='Greys', vmin=0, vmax=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
