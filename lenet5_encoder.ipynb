{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "print(tf.version.VERSION)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "    gpu = tf.config.experimental.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpu[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 32, 32, 1)\n",
      "(60000,)\n",
      "(10000, 32, 32, 1)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# load MNIST dataset\n",
    "# normalize data to 0~1 range\n",
    "data = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = data.load_data()\n",
    "\n",
    "x_train = np.pad(x_train, ((0,0), (2,2), (2,2)), 'constant', constant_values=0)\n",
    "x_train = x_train / 255.\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 32, 32, 1))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "x_test = np.pad(x_test, ((0,0), (2,2), (2,2)), 'constant', constant_values=0)\n",
    "x_test = x_test / 255.\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 32, 32, 1))\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lenet5_mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hand_writing_digit (InputLay [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "pool_1 (AveragePooling2D)    (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "pool_2 (AveragePooling2D)    (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "outputs (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load self-trained LeNet-5 model\n",
    "model_path = 'models/lenet5.h5'\n",
    "model_dir = os.path.dirname(model_path)\n",
    "lenet5_model = keras.models.load_model(model_dir)\n",
    "lenet5_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lenet5_mlp (Model)           (None, 10)                61706     \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "    lenet5_model,\n",
    "    tf.keras.layers.Softmax()\n",
    "])\n",
    "\n",
    "probability_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(x):\n",
    "    pred = probability_model(x)\n",
    "    indeces = np.argmax(pred, axis=1)\n",
    "    scores = np.max(pred, axis=1)\n",
    "    return list(zip(indeces, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9]\n",
      "[7 2 1 0 4 1 4 9 5 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(7, 1.0),\n",
       " (2, 1.0),\n",
       " (1, 0.9999982),\n",
       " (0, 0.9999999),\n",
       " (4, 0.9999201),\n",
       " (1, 1.0),\n",
       " (4, 0.99998486),\n",
       " (9, 1.0),\n",
       " (5, 0.9945539),\n",
       " (9, 1.0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test prediction\n",
    "pred = get_predictions(x_test[:10])\n",
    "print(y_test[:10])\n",
    "print(np.array([p[0] for p in pred]))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 1s - loss: 0.0434 - accuracy: 0.9898\n"
     ]
    }
   ],
   "source": [
    "loss, acc = lenet5_model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lenet5_encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hand_writing_digit (InputLay [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "pool_1 (AveragePooling2D)    (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "pool_2 (AveragePooling2D)    (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               48120     \n",
      "=================================================================\n",
      "Total params: 50,692\n",
      "Trainable params: 0\n",
      "Non-trainable params: 50,692\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# split model into encoder (convolutional layers) and dense-layer neural network\n",
    "# create encoder\n",
    "inputs = keras.Input(shape=(32,32,1), name='hand_writing_digit')\n",
    "x = keras.layers.Conv2D(filters=6, kernel_size=(5,5), activation='relu', name='conv2d_1')(inputs)\n",
    "x = keras.layers.AveragePooling2D((2,2), name='pool_1')(x)\n",
    "x = keras.layers.Conv2D(filters=16, kernel_size=(5,5), activation='relu', name='conv2d_2')(x)\n",
    "x = keras.layers.AveragePooling2D((2,2), name='pool_2')(x)\n",
    "x = keras.layers.Flatten(name='flatten')(x)\n",
    "outputs = keras.layers.Dense(120, activation='relu', name='dense_1')(x)\n",
    "\n",
    "encoder = keras.Model(inputs, outputs, name='lenet5_encoder')\n",
    "\n",
    "# load weights and loack the trained weights\n",
    "for encoder_layer, lenet5_layer in zip(encoder.layers, lenet5_model.layers[:7]):\n",
    "    encoder_layer.set_weights(lenet5_layer.get_weights())\n",
    "    encoder_layer.trainable = False\n",
    "\n",
    "# we don't compile encoder, since there's nothing to train the results are in the middel of LeNet-5\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed layer comparision test\n"
     ]
    }
   ],
   "source": [
    "# check weights\n",
    "for encoder_layer, lenet5_layer in zip(encoder.layers, lenet5_model.layers[:7]):\n",
    "    if len(encoder_layer.get_weights()) is not 0:\n",
    "        result = np.array_equal(\n",
    "            encoder_layer.get_weights()[0],\n",
    "            lenet5_layer.get_weights()[0])\n",
    "        if result is not True:\n",
    "            raise Exception('Unmatched weights')\n",
    "\n",
    "print('Passed layer comparision test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_nn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_img (InputLayer)     [(None, 120)]             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "outputs (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 11,014\n",
      "Trainable params: 0\n",
      "Non-trainable params: 11,014\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create dense-layer model\n",
    "inputs = keras.Input(shape=(120,), name='encoded_img')\n",
    "x = keras.layers.Dense(84, activation='relu', name='dense_2')(inputs)\n",
    "outputs = keras.layers.Dense(10, name='outputs')(x)\n",
    "\n",
    "dense_nn_model = keras.Model(inputs, outputs, name='dense_nn')\n",
    "\n",
    "# load weights and loack the trained weights\n",
    "for empty_layer, lenet5_layer in zip(dense_nn_model.layers[1:], lenet5_model.layers[-2:]):\n",
    "    empty_layer.set_weights(lenet5_layer.get_weights())\n",
    "    empty_layer.trainable = False\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "dense_nn_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=loss_fn,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "dense_nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed layer comparision test\n"
     ]
    }
   ],
   "source": [
    "# check weights\n",
    "for clone_layer, lenet5_layer in zip(dense_nn_model.layers[1:], lenet5_model.layers[-2:]):\n",
    "    if len(encoder_layer.get_weights()) is not 0:\n",
    "        result = np.array_equal(\n",
    "            clone_layer.get_weights()[0],\n",
    "            lenet5_layer.get_weights()[0])\n",
    "        if result is not True:\n",
    "            raise Exception('Unmatched weights')\n",
    "\n",
    "print('Passed layer comparision test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.0434 - accuracy: 0.9898\n"
     ]
    }
   ],
   "source": [
    "# use the coder and dense_nn models together\n",
    "lenet5_test_acc = 0.9898\n",
    "\n",
    "encoded_test = encoder.predict(x_test)\n",
    "loss, acc = dense_nn_model.evaluate(encoded_test, y_test, verbose=2)\n",
    "\n",
    "if not math.isclose(lenet5_test_acc, acc, rel_tol=1e-6):\n",
    "    raise Exception('Unmatched accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Adversarial examples using FGSM\n",
    "https://www.tensorflow.org/tutorials/generative/adversarial_fgsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use probability loss function instead of scalar\n",
    "def create_adversarial_perturbation(input_img, label):\n",
    "    if input_img.shape != (32, 32, 1):\n",
    "        raise Exception('Image size does not match', input_img.shape)\n",
    "    if not np.isscalar(label):\n",
    "        raise Exception('Label is a scalar')\n",
    "    \n",
    "    x = tf.convert_to_tensor([input_img])\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x)\n",
    "        pred = lenet5_model(x)\n",
    "        loss = loss_fn(tf.convert_to_tensor(label), pred)\n",
    "    \n",
    "    gradient = tape.gradient(loss, x)\n",
    "    signed_grad = tf.sign(gradient)\n",
    "    return signed_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n",
      "Ture label: 1\n",
      "Prediction: [(1, 0.9999943)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f97d828d1d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# idx = np.random.randint(0, len(y_test))\n",
    "idx = 143\n",
    "print(idx)\n",
    "print('Ture label:', y_test[idx])\n",
    "pred = get_predictions(np.array([x_test[idx]]))\n",
    "print('Prediction:', pred)\n",
    "plt.figure()\n",
    "plt.imshow(x_test[idx,:,:,0], cmap='Greys', vmin=0, vmax=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = x_test[idx]\n",
    "label = y_test[idx]\n",
    "pred = lenet5_model(tf.convert_to_tensor([img]))\n",
    "perturbation = create_adversarial_perturbation(img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f98492d6dd8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epsilon = 0.12\n",
    "adv_x = img + epsilon * perturbation\n",
    "# limited range to 0 and 1\n",
    "adv_x = tf.clip_by_value(adv_x, 0, 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(adv_x[0,:,:,0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8392264e-10 0.9999943 4.4899596e-07 8.7938054e-15 7.869149e-08 4.076708e-09 2.7621729e-08 2.5244198e-09 5.100235e-06 1.9555017e-11\n",
      "[(1, 0.9999943)]\n",
      "1.2440992e-06 0.23351192 0.0003077998 2.5040021e-09 3.1311018e-05 3.391754e-06 8.2271043e-07 7.6587696e-07 0.76614225 4.365325e-07\n",
      "[(8, 0.76614225)]\n",
      "Successfully found adversarial example\n"
     ]
    }
   ],
   "source": [
    "probs = probability_model(tf.convert_to_tensor([img]))\n",
    "pred = get_predictions(tf.convert_to_tensor([img]))\n",
    "print(*probs.numpy()[0])\n",
    "print(pred)\n",
    "\n",
    "adv_prbos = probability_model(adv_x)\n",
    "adv_pred = get_predictions(tf.convert_to_tensor(adv_x))\n",
    "print(*adv_prbos.numpy()[0])\n",
    "print(adv_pred)\n",
    "\n",
    "if pred[0][0] != adv_pred[0][0]:\n",
    "    print('Successfully found adversarial example')\n",
    "else:\n",
    "    print(f'Failed to find adversarial example from index {idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10000, 32, 32, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating adversarial examples on entire test set\n",
    "adv_test = tf.identity(x_test)\n",
    "adv_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-21.7321    -13.006052   -7.697587  ...  22.2667    -21.7904\n",
      "   -1.6543096]\n",
      " [ -3.7767682  -7.196234   24.247501  ... -13.555032  -21.55621\n",
      "  -28.96084  ]\n",
      " [-12.982773   10.776297   -3.012041  ...  -7.451107   -6.659894\n",
      "  -12.339667 ]\n",
      " ...\n",
      " [-23.01383    -7.100971  -13.039663  ... -17.160992  -17.405025\n",
      "   -3.70175  ]\n",
      " [-23.933226  -24.07146   -31.354671  ... -30.853754   -3.046572\n",
      "   -7.3496013]\n",
      " [ -6.429928  -16.44841   -10.386098  ... -27.551033  -30.660343\n",
      "  -13.524341 ]], shape=(10000, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pred_test = lenet5_model(tf.convert_to_tensor(x_test))\n",
    "print(pred_test)\n",
    "# for x, y in zip(adv_test, y_test):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
