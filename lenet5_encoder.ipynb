{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "print(tf.version.VERSION)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "    gpu = tf.config.experimental.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpu[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 32, 32, 1)\n",
      "(60000,)\n",
      "(10000, 32, 32, 1)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# load MNIST dataset\n",
    "# normalize data to 0~1 range\n",
    "data = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = data.load_data()\n",
    "\n",
    "x_train = np.pad(x_train, ((0,0), (2,2), (2,2)), 'constant', constant_values=0)\n",
    "x_train = x_train / 255.\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 32, 32, 1))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "x_test = np.pad(x_test, ((0,0), (2,2), (2,2)), 'constant', constant_values=0)\n",
    "x_test = x_test / 255.\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 32, 32, 1))\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lenet5_mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hand_writing_digit (InputLay [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "pool_1 (AveragePooling2D)    (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "pool_2 (AveragePooling2D)    (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "outputs (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load self-trained LeNet-5 model\n",
    "model_path = 'models/lenet5.h5'\n",
    "model_dir = os.path.dirname(model_path)\n",
    "lenet5_model = keras.models.load_model(model_dir)\n",
    "lenet5_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "    lenet5_model,\n",
    "    tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(x):\n",
    "    pred = probability_model(x)\n",
    "    indeces = np.argmax(pred, axis=1)\n",
    "    scores = np.max(pred, axis=1)\n",
    "    return list(zip(indeces, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9]\n",
      "[7 2 1 0 4 1 4 9 5 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(7, 1.0),\n",
       " (2, 1.0),\n",
       " (1, 0.9999982),\n",
       " (0, 0.9999999),\n",
       " (4, 0.9999201),\n",
       " (1, 1.0),\n",
       " (4, 0.99998486),\n",
       " (9, 1.0),\n",
       " (5, 0.9945539),\n",
       " (9, 1.0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test prediction\n",
    "pred = get_predictions(x_test[:10])\n",
    "print(y_test[:10])\n",
    "print(np.array([p[0] for p in pred]))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 1s - loss: 0.0434 - accuracy: 0.9898\n"
     ]
    }
   ],
   "source": [
    "loss, acc = lenet5_model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lenet5_encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hand_writing_digit (InputLay [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "pool_1 (AveragePooling2D)    (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "pool_2 (AveragePooling2D)    (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               48120     \n",
      "=================================================================\n",
      "Total params: 50,692\n",
      "Trainable params: 0\n",
      "Non-trainable params: 50,692\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# split model into encoder (convolutional layers) and dense-layer neural network\n",
    "# create encoder\n",
    "inputs = keras.Input(shape=(32,32,1), name='hand_writing_digit')\n",
    "x = keras.layers.Conv2D(filters=6, kernel_size=(5,5), activation='relu', name='conv2d_1')(inputs)\n",
    "x = keras.layers.AveragePooling2D((2,2), name='pool_1')(x)\n",
    "x = keras.layers.Conv2D(filters=16, kernel_size=(5,5), activation='relu', name='conv2d_2')(x)\n",
    "x = keras.layers.AveragePooling2D((2,2), name='pool_2')(x)\n",
    "x = keras.layers.Flatten(name='flatten')(x)\n",
    "outputs = keras.layers.Dense(120, activation='relu', name='dense_1')(x)\n",
    "\n",
    "encoder = keras.Model(inputs, outputs, name='lenet5_encoder')\n",
    "\n",
    "# load weights and loack the trained weights\n",
    "for encoder_layer, lenet5_layer in zip(encoder.layers, lenet5_model.layers[:7]):\n",
    "    encoder_layer.set_weights(lenet5_layer.get_weights())\n",
    "    encoder_layer.trainable = False\n",
    "\n",
    "# we don't compile encoder, since there's nothing to train the results are in the middel of LeNet-5\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed layer comparision test\n"
     ]
    }
   ],
   "source": [
    "# check weights\n",
    "for encoder_layer, lenet5_layer in zip(encoder.layers, lenet5_model.layers[:7]):\n",
    "    if len(encoder_layer.get_weights()) is not 0:\n",
    "        result = np.array_equal(\n",
    "            encoder_layer.get_weights()[0],\n",
    "            lenet5_layer.get_weights()[0])\n",
    "        if result is not True:\n",
    "            raise Exception('Unmatched weights')\n",
    "\n",
    "print('Passed layer comparision test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_nn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_img (InputLayer)     [(None, 120)]             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "outputs (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 11,014\n",
      "Trainable params: 0\n",
      "Non-trainable params: 11,014\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create dense-layer model\n",
    "inputs = keras.Input(shape=(120,), name='encoded_img')\n",
    "x = keras.layers.Dense(84, activation='relu', name='dense_2')(inputs)\n",
    "outputs = keras.layers.Dense(10, name='outputs')(x)\n",
    "\n",
    "dense_nn_model = keras.Model(inputs, outputs, name='dense_nn')\n",
    "\n",
    "# load weights and loack the trained weights\n",
    "for empty_layer, lenet5_layer in zip(dense_nn_model.layers[1:], lenet5_model.layers[-2:]):\n",
    "    empty_layer.set_weights(lenet5_layer.get_weights())\n",
    "    empty_layer.trainable = False\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "dense_nn_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=loss_fn,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "dense_nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed layer comparision test\n"
     ]
    }
   ],
   "source": [
    "# check weights\n",
    "for clone_layer, lenet5_layer in zip(dense_nn_model.layers[1:], lenet5_model.layers[-2:]):\n",
    "    if len(encoder_layer.get_weights()) is not 0:\n",
    "        result = np.array_equal(\n",
    "            clone_layer.get_weights()[0],\n",
    "            lenet5_layer.get_weights()[0])\n",
    "        if result is not True:\n",
    "            raise Exception('Unmatched weights')\n",
    "\n",
    "print('Passed layer comparision test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.0434 - accuracy: 0.9898\n"
     ]
    }
   ],
   "source": [
    "# use the coder and dense_nn models together\n",
    "lenet5_test_acc = 0.9898\n",
    "\n",
    "encoded_test = encoder.predict(x_test)\n",
    "loss, acc = dense_nn_model.evaluate(encoded_test, y_test, verbose=2)\n",
    "\n",
    "if not math.isclose(lenet5_test_acc, acc, rel_tol=1e-6):\n",
    "    raise Exception('Unmatched accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1928\n",
      "Ture label: 3\n",
      "Prediction: [(3, 0.99999964)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fad5db51210>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(0, len(y_test))\n",
    "print(idx)\n",
    "print('Ture label:', y_test[idx])\n",
    "pred = get_predictions(np.array([x_test[idx]]))\n",
    "print('Prediction:', pred)\n",
    "plt.figure()\n",
    "plt.imshow(x_test[idx,:,:,0], cmap='Greys', vmin=0, vmax=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = tf.convert_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (32, 32, 1)\n",
      "label: 3\n",
      "tf.Tensor(\n",
      "[-28.924875   -5.4111853  -8.709516   19.083963  -18.57442     4.1780887\n",
      " -19.269346   -5.291358  -10.114314   -7.2766967], shape=(10,), dtype=float32)\n",
      "loss: 3.576278e-07\n"
     ]
    }
   ],
   "source": [
    "# computing loss for single image\n",
    "img = x_test[idx]\n",
    "print('Image shape:', img.shape)\n",
    "label = y_test[idx]\n",
    "print('label:', label)\n",
    "pred = lenet5_model(to_tensor([img]))\n",
    "print(*pred)\n",
    "loss = loss_fn(to_tensor(label), pred)\n",
    "print('loss:', loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Adversarial examples using FGSM\n",
    "https://www.tensorflow.org/tutorials/generative/adversarial_fgsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faceb102390>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = to_tensor([img])\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    pred = lenet5_model(x)\n",
    "    loss = loss_fn(to_tensor(label), pred)\n",
    "\n",
    "gradient = tape.gradient(loss, x)\n",
    "signed_grad = tf.sign(gradient)\n",
    "print(signed_grad.shape)\n",
    "plt.figure()\n",
    "plt.imshow(signed_grad[0,:,:,0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adversarial_example(clean_img, label):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
